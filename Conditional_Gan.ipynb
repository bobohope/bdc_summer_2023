{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bobohope/bdc_summer_2023/blob/main/Conditional_Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXUs8sYI0bqm"
      },
      "source": [
        "# Conditional GAN\n",
        "\n",
        "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/07/13<br>\n",
        "**Last modified:** 2021/07/15<br>\n",
        "**Description:** Training a GAN conditioned on class labels to generate handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTD40cmw0bqq"
      },
      "source": [
        "Generative Adversarial Networks (GANs) let us generate novel image data, video data,\n",
        "or audio data from a random input. Typically, the random input is sampled\n",
        "from a normal distribution, before going through a series of transformations that turn\n",
        "it into something plausible (image, video, audio, etc.).\n",
        "\n",
        "However, a simple [DCGAN](https://arxiv.org/abs/1511.06434) doesn't let us control\n",
        "the appearance (e.g. class) of the samples we're generating. For instance,\n",
        "with a GAN that generates MNIST handwritten digits, a simple DCGAN wouldn't let us\n",
        "choose the class of digits we're generating.\n",
        "To be able to control what we generate, we need to _condition_ the GAN output\n",
        "on a semantic input, such as the class of an image.\n",
        "\n",
        "In this example, we'll build a **Conditional GAN** that can generate MNIST handwritten\n",
        "digits conditioned on a given class. Such a model can have various useful applications:\n",
        "\n",
        "* let's say you are dealing with an\n",
        "[imbalanced image dataset](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data),\n",
        "and you'd like to gather more examples for the skewed class to balance the dataset.\n",
        "Data collection can be a costly process on its own. You could instead train a Conditional GAN and use\n",
        "it to generate novel images for the class that needs balancing.\n",
        "* Since the generator learns to associate the generated samples with the class labels,\n",
        "its representations can also be used for [other downstream tasks](https://arxiv.org/abs/1809.11096).\n",
        "\n",
        "Following are the references used for developing this example:\n",
        "\n",
        "* [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784)\n",
        "* [Lecture on Conditional Generation from Coursera](https://www.coursera.org/lecture/build-basic-generative-adversarial-networks-gans/conditional-generation-inputs-2OPrG)\n",
        "\n",
        "If you need a refresher on GANs, you can refer to the \"Generative adversarial networks\"\n",
        "section of\n",
        "[this resource](https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-12/r-3/232).\n",
        "\n",
        "This example requires TensorFlow 2.5 or higher, as well as TensorFlow Docs, which can be\n",
        "installed using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MJCD8drX0bqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2a9a19-fe5c-4fd6-c193-8b85640f1d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Lz0qJM0bqs"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xXFG_zfK09Hk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cFbkKSbH0bqt"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow_docs.vis import embed\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_RvW4Hy0bqt"
      },
      "source": [
        "## Constants and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k2BuQP6g0bqt"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_channels = 1\n",
        "image_size = 16\n",
        "latent_dim = 128\n",
        "hold_out_frac = 0.1\n",
        "positive_threshold = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3fU_cY-0bqu"
      },
      "source": [
        "## Loading the MNIST dataset and preprocessing it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdt2QpVpH4zz",
        "outputId": "44743c75-3572-4834-88b2-8bc06fbb3bae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXh1nRJsIZqe"
      },
      "source": [
        "google_drive_dir = \"/content/gdrive/My Drive/gan_data/\"\n",
        "# !mkdir \"$google_drive_dir\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = pd.read_csv(google_drive_dir+'final_data_20231115.csv', sep='\\t')"
      ],
      "metadata": {
        "id": "PQBXlQkk08CV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "BNSxZRyV1UWM",
        "outputId": "05337b42-2635-4dd2-b2d6-b9d84390c5d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                lat_lon  month  year      snom     csnow  \\\n",
              "0               0  (25.21298, -80.80556)      1  2022  0.000000  0.000000   \n",
              "1               1  (25.21298, -80.80556)      2  2022  0.000000  0.000000   \n",
              "2               2  (25.21298, -80.80556)      4  2022  0.000000  0.000000   \n",
              "3               3  (25.21298, -80.80556)      9  2022  0.000000  0.000000   \n",
              "4               4  (25.21298, -80.80556)     10  2022  0.000000  0.000000   \n",
              "...           ...                    ...    ...   ...       ...       ...   \n",
              "67296       67296  (72.95542, -84.72343)      6  2022  0.130371  0.183333   \n",
              "67297       67297  (73.02668, -79.89407)      6  2022  0.312533  0.241667   \n",
              "67298       67298  (73.83063, -120.6265)      6  2022  0.506478  0.133333   \n",
              "67299       67299  (74.13185, -119.8663)      6  2022  0.450293  0.145833   \n",
              "67300       67300   (74.68508, -94.7833)      7  2022  0.643051  0.000000   \n",
              "\n",
              "             air        vis      apcp      evap  ...  Bucephala albeola  \\\n",
              "0      293.15067  18463.783  1.783782  0.243646  ...                  0   \n",
              "1      295.28534  17220.467  1.062557  0.304188  ...                  0   \n",
              "2      298.49300  18676.670  1.928958  0.348559  ...                  0   \n",
              "3      302.05057  17731.424  7.805038  0.406399  ...                  0   \n",
              "4      299.10720  18337.787  2.369916  0.311079  ...                  0   \n",
              "...          ...        ...       ...       ...  ...                ...   \n",
              "67296  276.19928  16246.982  0.947968  0.213672  ...                  0   \n",
              "67297  273.96857  14880.315  1.077916  0.189339  ...                  0   \n",
              "67298  272.50894   9324.483  0.855000  0.018955  ...                  0   \n",
              "67299  272.75400  10686.983  0.921406  0.019043  ...                  0   \n",
              "67300  280.55570  17145.734  0.238819  0.117931  ...                  0   \n",
              "\n",
              "       Lophodytes cucullatus  Mareca strepera  Mareca americana  \\\n",
              "0                          0                1                 1   \n",
              "1                          0                0                 0   \n",
              "2                          0                0                 0   \n",
              "3                          0                0                 0   \n",
              "4                          0                0                 0   \n",
              "...                      ...              ...               ...   \n",
              "67296                      0                0                 0   \n",
              "67297                      0                0                 0   \n",
              "67298                      0                0                 0   \n",
              "67299                      0                0                 0   \n",
              "67300                      0                0                 0   \n",
              "\n",
              "       Aythya collaris  Cygnus olor  Mergus serrator  Spatula clypeata  \\\n",
              "0                    1            0                0                 1   \n",
              "1                    0            0                0                 0   \n",
              "2                    0            0                0                 0   \n",
              "3                    0            0                0                 0   \n",
              "4                    0            0                0                 0   \n",
              "...                ...          ...              ...               ...   \n",
              "67296                0            0                0                 0   \n",
              "67297                0            0                1                 0   \n",
              "67298                0            0                0                 0   \n",
              "67299                0            0                0                 0   \n",
              "67300                0            0                0                 0   \n",
              "\n",
              "       Mergus merganser  Spatula discors  \n",
              "0                     0                1  \n",
              "1                     0                1  \n",
              "2                     0                1  \n",
              "3                     0                1  \n",
              "4                     0                1  \n",
              "...                 ...              ...  \n",
              "67296                 0                0  \n",
              "67297                 0                0  \n",
              "67298                 0                0  \n",
              "67299                 0                0  \n",
              "67300                 0                0  \n",
              "\n",
              "[67301 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b19d53e-f44b-4f31-ae0c-d847d061e880\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>lat_lon</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>snom</th>\n",
              "      <th>csnow</th>\n",
              "      <th>air</th>\n",
              "      <th>vis</th>\n",
              "      <th>apcp</th>\n",
              "      <th>evap</th>\n",
              "      <th>...</th>\n",
              "      <th>Bucephala albeola</th>\n",
              "      <th>Lophodytes cucullatus</th>\n",
              "      <th>Mareca strepera</th>\n",
              "      <th>Mareca americana</th>\n",
              "      <th>Aythya collaris</th>\n",
              "      <th>Cygnus olor</th>\n",
              "      <th>Mergus serrator</th>\n",
              "      <th>Spatula clypeata</th>\n",
              "      <th>Mergus merganser</th>\n",
              "      <th>Spatula discors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>(25.21298, -80.80556)</td>\n",
              "      <td>1</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>293.15067</td>\n",
              "      <td>18463.783</td>\n",
              "      <td>1.783782</td>\n",
              "      <td>0.243646</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>(25.21298, -80.80556)</td>\n",
              "      <td>2</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>295.28534</td>\n",
              "      <td>17220.467</td>\n",
              "      <td>1.062557</td>\n",
              "      <td>0.304188</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>(25.21298, -80.80556)</td>\n",
              "      <td>4</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>298.49300</td>\n",
              "      <td>18676.670</td>\n",
              "      <td>1.928958</td>\n",
              "      <td>0.348559</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>(25.21298, -80.80556)</td>\n",
              "      <td>9</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>302.05057</td>\n",
              "      <td>17731.424</td>\n",
              "      <td>7.805038</td>\n",
              "      <td>0.406399</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>(25.21298, -80.80556)</td>\n",
              "      <td>10</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>299.10720</td>\n",
              "      <td>18337.787</td>\n",
              "      <td>2.369916</td>\n",
              "      <td>0.311079</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67296</th>\n",
              "      <td>67296</td>\n",
              "      <td>(72.95542, -84.72343)</td>\n",
              "      <td>6</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.130371</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>276.19928</td>\n",
              "      <td>16246.982</td>\n",
              "      <td>0.947968</td>\n",
              "      <td>0.213672</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67297</th>\n",
              "      <td>67297</td>\n",
              "      <td>(73.02668, -79.89407)</td>\n",
              "      <td>6</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.312533</td>\n",
              "      <td>0.241667</td>\n",
              "      <td>273.96857</td>\n",
              "      <td>14880.315</td>\n",
              "      <td>1.077916</td>\n",
              "      <td>0.189339</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67298</th>\n",
              "      <td>67298</td>\n",
              "      <td>(73.83063, -120.6265)</td>\n",
              "      <td>6</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.506478</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>272.50894</td>\n",
              "      <td>9324.483</td>\n",
              "      <td>0.855000</td>\n",
              "      <td>0.018955</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67299</th>\n",
              "      <td>67299</td>\n",
              "      <td>(74.13185, -119.8663)</td>\n",
              "      <td>6</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.450293</td>\n",
              "      <td>0.145833</td>\n",
              "      <td>272.75400</td>\n",
              "      <td>10686.983</td>\n",
              "      <td>0.921406</td>\n",
              "      <td>0.019043</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67300</th>\n",
              "      <td>67300</td>\n",
              "      <td>(74.68508, -94.7833)</td>\n",
              "      <td>7</td>\n",
              "      <td>2022</td>\n",
              "      <td>0.643051</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>280.55570</td>\n",
              "      <td>17145.734</td>\n",
              "      <td>0.238819</td>\n",
              "      <td>0.117931</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67301 rows Ã— 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b19d53e-f44b-4f31-ae0c-d847d061e880')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b19d53e-f44b-4f31-ae0c-d847d061e880 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b19d53e-f44b-4f31-ae0c-d847d061e880');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d77a403-daeb-4cb9-a1ec-98ce483b23b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d77a403-daeb-4cb9-a1ec-98ce483b23b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d77a403-daeb-4cb9-a1ec-98ce483b23b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "species_picked = ['Branta canadensis',\n",
        "                  'Anas platyrhynchos',\n",
        "                  'Anas crecca',\n",
        "                  'Anas rubripes',\n",
        "                  'Bucephala clangula',\n",
        "                  'Aix sponsa',\n",
        "                  'Bucephala albeola',\n",
        "                  'Lophodytes cucullatus',\n",
        "                  'Mareca strepera',\n",
        "                  'Mareca americana',\n",
        "                  'Aythya collaris',\n",
        "                  'Cygnus olor',\n",
        "                  'Mergus serrator',\n",
        "                  'Spatula clypeata',\n",
        "                  'Mergus merganser',\n",
        "                  'Spatula discors',\n",
        "                 ]\n",
        "# conditional_features = [\n",
        "#     'snom', 'csnow', 'air', 'vis', 'apcp', 'evap',\n",
        "#        'crain', 'uwnd', 'vwnd', 'weasd', 'ccond', 'mstav', 'wspd', 'cicep',\n",
        "#        'prate', 'lftx4', 'rhum', 'snowc', 'tcdc', 'albedo', 'veg', 'snod',\n",
        "#        'hlcy', 'cfrzr'\n",
        "# ]\n",
        "conditional_features = [\n",
        "'prate', 'lftx4', 'rhum', 'snowc', 'tcdc', 'albedo', 'veg', 'snod',\n",
        "        'hlcy', 'cfrzr'\n",
        "]\n",
        "num_conditional_features = len(conditional_features) # environmental variables\n"
      ],
      "metadata": {
        "id": "UNLtOxVhzjLv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(training_data, test_size=hold_out_frac, random_state=42)"
      ],
      "metadata": {
        "id": "1iNwy73bzsjV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "species = X_train[species_picked].values\n",
        "# construct 2d image using species prestentation data\n",
        "# dimension for each patch is [16,16]\n",
        "n_tile = 16\n",
        "species_2D = np.asarray([np.transpose(np.tile(item, (n_tile,1))) for item in species])\n",
        "# species_2D = np.tile(species, (1,1,n_tile))\n",
        "# plot data\n"
      ],
      "metadata": {
        "id": "Lz2SgnZY0AYL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "e1_Fgju-8CCS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # save image\n",
        "# dir_name = google_drive_dir+'images_for_GAN_training/'\n",
        "# try:\n",
        "#     shutil.rmtree(dir_name)\n",
        "# except OSError as e:\n",
        "#   pass\n",
        "\n",
        "# print(f'Creating directories ...')\n",
        "# os.mkdir(dir_name)\n",
        "\n",
        "# dir_name=os.path.join(dir_name,'real_patches/')\n",
        "# IMAGE_PATH= dir_name\n",
        "\n",
        "# if not os.path.exists(dir_name):\n",
        "#       os.mkdir(dir_name)\n",
        "\n",
        "# n_patches = species_2D.shape[0]\n",
        "\n",
        "# print(f'... saving Images ...')\n",
        "# for j in range(n_patches):\n",
        "#     array = species_2D[j,:,:]\n",
        "#     array = (array * 255).astype(np.uint8)\n",
        "\n",
        "#     Image.fromarray(array).convert('L').save(os.path.join(dir_name,str(j)+'.png'))\n",
        "\n",
        "# print('... a total of {} images saved at directory {}'.format(n_patches,dir_name))"
      ],
      "metadata": {
        "id": "TISeG7nI3YY_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# from matplotlib import pyplot as plt\n",
        "# import random\n",
        "# fig, ax = plt.subplots(1, 6, figsize=(25,100))\n",
        "\n",
        "# for x in range(0,6) :\n",
        "#   im = Image.open(os.path.join(dir_name,str(random.randint(0,species_2D.shape[0]))+'.png'))\n",
        "#   ax[x].imshow(im)\n",
        "\n",
        "# plt.show()\n",
        "# plt.tight_layout()"
      ],
      "metadata": {
        "id": "izIfBC4E3EBU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conditional_input = X_train[conditional_features].values\n",
        "mean = conditional_input.mean(axis=0)\n",
        "std = conditional_input.std(axis=0)\n",
        "conditional_input_std = (conditional_input - mean) / std\n",
        "\n",
        "conditional_input_std = np.float32(conditional_input_std)\n",
        "# normalize conditional input\n"
      ],
      "metadata": {
        "id": "vjGLp8xWbvX1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conditional_input_std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTPRwcfDdXyL",
        "outputId": "45e982a6-e608-4fb4-ab24-f6cd201a649d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.46910113,  0.10261691, -0.90324706, ..., -0.2446004 ,\n",
              "        -0.29286382, -0.25522688],\n",
              "       [ 4.0897665 , -0.26095766,  1.393767  , ..., -0.23752011,\n",
              "        -0.44377932, -0.25522688],\n",
              "       [-1.0750395 , -0.8574995 , -1.340351  , ..., -0.2446004 ,\n",
              "        -0.9194975 , -0.25522688],\n",
              "       ...,\n",
              "       [-0.8688636 , -0.13979453, -0.0354595 , ...,  0.02223363,\n",
              "         0.42591736, -0.25522688],\n",
              "       [ 4.9617157 , -1.7911695 ,  0.8956647 , ..., -0.2446004 ,\n",
              "        -1.5153422 , -0.25522688],\n",
              "       [-0.5660201 ,  0.4773921 ,  0.21861863, ..., -0.24459659,\n",
              "        -0.5324463 , -0.25522688]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conditional_input = np.float32(X_train[conditional_features].values)\n",
        "species_reshape = np.reshape(species_2D, (-1, 16, 16, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((species_reshape, conditional_input_std))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "metadata": {
        "id": "zA-o_FOv2cp-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mr4HYU4K0bqu"
      },
      "outputs": [],
      "source": [
        "# # We'll use all the available examples from both the training and test\n",
        "# # sets.\n",
        "# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "# all_digits = np.concatenate([x_train, x_test])\n",
        "# all_labels = np.concatenate([y_train, y_test])\n",
        "\n",
        "# # Scale the pixel values to [0, 1] range, add a channel dimension to\n",
        "# # the images, and one-hot encode the labels.\n",
        "# all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "# all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "# all_labels = keras.utils.to_categorical(all_labels, 10)\n",
        "\n",
        "# # Create tf.data.Dataset.\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
        "# dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# print(f\"Shape of training images: {all_digits.shape}\")\n",
        "# print(f\"Shape of training labels: {all_labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzIa5SGp0bqv"
      },
      "source": [
        "## Calculating the number of input channel for the generator and discriminator\n",
        "\n",
        "In a regular (unconditional) GAN, we start by sampling noise (of some fixed\n",
        "dimension) from a normal distribution. In our case, we also need to account\n",
        "for the class labels. We will have to add the number of classes to\n",
        "the input channels of the generator (noise input) as well as the discriminator\n",
        "(generated image input)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OIqbCR9W0bqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e547a38f-91dd-4bec-a7ed-adfeefec5a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138 11\n"
          ]
        }
      ],
      "source": [
        "generator_in_channels = latent_dim + num_conditional_features\n",
        "discriminator_in_channels = num_channels + num_conditional_features\n",
        "print(generator_in_channels, discriminator_in_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SbML8_b0bqv"
      },
      "source": [
        "## Creating the discriminator and generator\n",
        "\n",
        "The model definitions (`discriminator`, `generator`, and `ConditionalGAN`) have been\n",
        "adapted from [this example](https://keras.io/guides/customizing_what_happens_in_fit/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "f_Xi2q6T0bqv"
      },
      "outputs": [],
      "source": [
        "# Create the discriminator.\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.InputLayer((16, 16, discriminator_in_channels)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.InputLayer((generator_in_channels,)),\n",
        "        # We want to generate latent_dim + num_classes coefficients to reshape into a\n",
        "        # 7x7x(latent_dim + num_classes) map.\n",
        "        layers.Dense(4 * 4 * generator_in_channels),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((4, 4, generator_in_channels)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, (4, 4), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PboDZt4r0bqw"
      },
      "source": [
        "## Creating a `ConditionalGAN` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mvSctdCd0bqw"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConditionalGAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data.\n",
        "        real_images, one_hot_labels = data\n",
        "\n",
        "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
        "        # the images. This is for the discriminator.\n",
        "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "        image_one_hot_labels = tf.repeat(\n",
        "            image_one_hot_labels, repeats=[image_size * image_size]\n",
        "        )\n",
        "        image_one_hot_labels = tf.reshape(\n",
        "            image_one_hot_labels, (-1, image_size, image_size, num_conditional_features)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space and concatenate the labels.\n",
        "        # This is for the generator.\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        random_vector_labels = tf.concat(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # Decode the noise (guided by labels) to fake images.\n",
        "        generated_images = self.generator(random_vector_labels)\n",
        "\n",
        "        # print(generated_images.get_shape())\n",
        "        # print(image_one_hot_labels.get_shape())\n",
        "        # print(real_images.get_shape())\n",
        "        real_images = tf.cast(real_images, tf.float32)\n",
        "        # Combine them with real images. Note that we are concatenating the labels\n",
        "        # with these images here.\n",
        "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
        "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
        "        combined_images = tf.concat(\n",
        "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
        "        )\n",
        "\n",
        "        # Assemble labels discriminating real from fake images.\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # Train the discriminator.\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space.\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        random_vector_labels = tf.concat(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # Assemble labels that say \"all real images\".\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_images = self.generator(random_vector_labels)\n",
        "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
        "            predictions = self.discriminator(fake_image_and_labels)\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Monitor loss.\n",
        "        self.gen_loss_tracker.update_state(g_loss)\n",
        "        self.disc_loss_tracker.update_state(d_loss)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6AF1ajL0bqw"
      },
      "source": [
        "## Training the Conditional GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "3EK6pO3B0bqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9ea68d-c1c4-4c77-c36a-a0d3f7c1422e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 2208)              306912    \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 2208)              0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 4, 4, 138)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 8, 8, 128)         282752    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 16, 16, 128)       262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 1)         2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 853985 (3.26 MB)\n",
            "Trainable params: 853985 (3.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "947/947 [==============================] - 16s 13ms/step - g_loss: 1.1215 - d_loss: 0.5717\n",
            "Epoch 2/20\n",
            "947/947 [==============================] - 16s 17ms/step - g_loss: 1.2089 - d_loss: 0.5230\n",
            "Epoch 3/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.1064 - d_loss: 0.5461\n",
            "Epoch 4/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.0290 - d_loss: 0.5602\n",
            "Epoch 5/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.1349 - d_loss: 0.5376\n",
            "Epoch 6/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.2322 - d_loss: 0.5213\n",
            "Epoch 7/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.3096 - d_loss: 0.5080\n",
            "Epoch 8/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.4038 - d_loss: 0.4961\n",
            "Epoch 9/20\n",
            "947/947 [==============================] - 13s 13ms/step - g_loss: 1.4742 - d_loss: 0.4861\n",
            "Epoch 10/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.5838 - d_loss: 0.4651\n",
            "Epoch 11/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.7001 - d_loss: 0.4488\n",
            "Epoch 12/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.7919 - d_loss: 0.4617\n",
            "Epoch 13/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 1.8859 - d_loss: 0.4516\n",
            "Epoch 14/20\n",
            "947/947 [==============================] - 13s 13ms/step - g_loss: 1.9845 - d_loss: 0.4397\n",
            "Epoch 15/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 2.0524 - d_loss: 0.4365\n",
            "Epoch 16/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 2.0600 - d_loss: 0.4354\n",
            "Epoch 17/20\n",
            "947/947 [==============================] - 13s 14ms/step - g_loss: 2.1762 - d_loss: 0.4242\n",
            "Epoch 18/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 2.2424 - d_loss: 0.4222\n",
            "Epoch 19/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 2.3884 - d_loss: 0.3893\n",
            "Epoch 20/20\n",
            "947/947 [==============================] - 12s 13ms/step - g_loss: 2.3825 - d_loss: 0.4097\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ea968de1ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "cond_gan = ConditionalGAN(\n",
        "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
        ")\n",
        "cond_gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "print(cond_gan.generator.summary())\n",
        "\n",
        "cond_gan.fit(dataset, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_drive_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u5VX4JzLPxBK",
        "outputId": "ed8eb246-6e88-461f-e52b-768262f02fc4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/gan_data/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the gan model\n",
        "# cond_gan.save(google_drive_dir+'model/cond_gan.keras')\n",
        "# ! mkdir \"${google_drive_dir}model/cond_gan_generator.keras\"\n",
        "# cond_gan.generator.save('cond_gan_generator.keras')\n",
        "cond_gan.generator.save(google_drive_dir+ 'cond_gan_generator.keras')\n",
        "cond_gan.save(google_drive_dir+ 'cond_gan.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4wq_z7WAk5x",
        "outputId": "f16afc0a-c322-4312-d9fe-3abef6b91126"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:164: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
            "  saving_lib.save_model(model, filepath)\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObDZ7SwT0bqx"
      },
      "source": [
        "## Interpolating between classes with the trained generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "dN1gOoGh0bqx"
      },
      "outputs": [],
      "source": [
        "# We first extract the trained generator from our Conditional GAN.\n",
        "trained_gen = cond_gan.generator\n",
        "\n",
        "# Choose the number of intermediate images that would be generated in\n",
        "# between the interpolation + 2 (start and last images).\n",
        "num_interpolation = 9  # @param {type:\"integer\"}\n",
        "\n",
        "# Sample noise for the interpolation.\n",
        "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
        "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
        "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
        "\n",
        "def generate_fake(conditional_input):\n",
        "    # conditional_input_cast = tf.cast(conditional_input, tf.float32)\n",
        "    conditional_input_repeat = tf.repeat(conditional_input, repeats=num_interpolation)\n",
        "    conditional_input_repeat = tf.reshape(conditional_input_repeat, [9,10])\n",
        "    noise_and_conditional_input = tf.concat([interpolation_noise, conditional_input_repeat], 1)\n",
        "    fake = trained_gen.predict(noise_and_conditional_input)\n",
        "    return fake\n",
        "# def interpolate_class(first_number, second_number):\n",
        "#     # Convert the start and end labels to one-hot encoded vectors.\n",
        "#     first_label = keras.utils.to_categorical([first_number], num_classes)\n",
        "#     second_label = keras.utils.to_categorical([second_number], num_classes)\n",
        "#     first_label = tf.cast(first_label, tf.float32)\n",
        "#     second_label = tf.cast(second_label, tf.float32)\n",
        "\n",
        "#     # Calculate the interpolation vector between the two labels.\n",
        "#     percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
        "#     percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
        "#     interpolation_labels = (\n",
        "#         first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
        "#     )\n",
        "\n",
        "#     # Combine the noise and the labels and run inference with the generator.\n",
        "#     noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
        "#     fake = trained_gen.predict(noise_and_labels)\n",
        "#     return fake\n",
        "\n",
        "\n",
        "# start_class = 1  # @param {type:\"slider\", min:0, max:9, step:1}\n",
        "# end_class = 5  # @param {type:\"slider\", min:0, max:9, step:1}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrwe_4tpRSLo",
        "outputId": "21531fe1-02bb-415a-96df-df327eb31d61"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conditional_input = X_test[conditional_features].values[1]"
      ],
      "metadata": {
        "id": "fgyXBWEbO_TH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conditional_input_std = np.float32((conditional_input - mean) / std)"
      ],
      "metadata": {
        "id": "W2RY62NaRJCC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_2eg8rK0bqx"
      },
      "source": [
        "Here, we first sample noise from a normal distribution and then we repeat that for\n",
        "`num_interpolation` times and reshape the result accordingly.\n",
        "We then distribute it uniformly for `num_interpolation`\n",
        "with the label identities being present in some proportion."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_images = generate_fake(conditional_input_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irFUOOfROzdA",
        "outputId": "409ede7a-9ed7-46f9-c7c7-251d7d3d9ff1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fake_images [0]"
      ],
      "metadata": {
        "id": "u74jGlZ0Valt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "xMuKXZSp0bqx"
      },
      "outputs": [],
      "source": [
        "fake_images *= 255.0\n",
        "converted_images = fake_images.astype(np.uint8)\n",
        "converted_images = tf.image.resize(converted_images, (16, 16)).numpy().astype(np.uint8)\n",
        "\n",
        "\n",
        "# imageio.mimsave(\"animation.gif\", converted_images, fps=1)\n",
        "# embed.embed_file(\"animation.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKY0U1yR0bqx"
      },
      "source": [
        "We can further improve the performance of this model with recipes like\n",
        "[WGAN-GP](https://keras.io/examples/generative/wgan_gp).\n",
        "Conditional generation is also widely used in many modern image generation architectures like\n",
        "[VQ-GANs](https://arxiv.org/abs/2012.09841), [DALL-E](https://openai.com/blog/dall-e/),\n",
        "etc.\n",
        "\n",
        "You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/conditional-gan) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/conditional-GAN)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "fig, ax = plt.subplots(1, 6, figsize=(25,100))\n",
        "\n",
        "for x in range(0,6) :\n",
        "  # im = Image.open(os.path.join(dir_name,str(random.randint(0,species_2D.shape[0]))+'.png'))\n",
        "  ax[x].imshow(converted_images[x])\n",
        "\n",
        "plt.show()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "OBv67jstU6Lq",
        "outputId": "a173191b-77c9-4493-c83d-5c7324c95501"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x10000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54YoUXpZVFix"
      },
      "execution_count": 40,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}